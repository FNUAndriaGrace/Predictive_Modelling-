{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c033e94",
   "metadata": {},
   "source": [
    "# Exercise 22.1. \n",
    "#### (Part a, b , c , d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0f3e911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Part (a):\n",
      "Regression coefficients: [ 9.82034999e-01  2.10357510e+00 -4.12871821e-03 -1.19045302e-01\n",
      " -5.91502722e-02  2.81444400e-02  1.11157184e-02  1.41155808e-02\n",
      " -4.73444541e-02 -1.00963053e-02 -5.79910225e-02  2.79101242e-02\n",
      " -3.61900354e-02 -5.15215298e-02  6.69218241e-02  3.18423081e-02\n",
      "  1.53709725e-02 -1.96664044e-02  7.31117887e-02 -8.30356798e-02\n",
      "  1.85189653e-02  1.88322040e-02 -4.01963168e-02  1.07927450e-01\n",
      " -3.57669049e-02  1.03944140e-01 -1.81992313e-02 -1.20484489e-02\n",
      " -1.14489520e-02 -5.34810289e-02 -4.14714178e-03  3.83724014e-02\n",
      " -3.10481221e-02 -2.70874265e-03  6.70755236e-02 -3.15182153e-02\n",
      " -1.91247132e-03  4.48305814e-02 -6.19855144e-02  1.39970602e-02\n",
      " -4.69915946e-02  3.78213472e-02  4.37822286e-02 -9.37532301e-03\n",
      "  3.79619778e-02  7.69124757e-03  4.80254469e-02 -2.28861683e-02\n",
      "  2.84167108e-02 -5.44728250e-02  2.07638873e-02  1.39734795e-02\n",
      " -4.35401843e-02 -4.52582217e-02  9.79795847e-02 -5.90708341e-02\n",
      " -3.54309079e-02 -9.29561854e-03  1.09422408e-02  5.08248700e-04\n",
      "  6.47201827e-03 -1.09857269e-01 -2.93108026e-02 -9.95186824e-03\n",
      "  2.38470201e-02 -8.82329526e-02  5.65555612e-02  4.70511191e-02\n",
      " -4.60296587e-02 -4.47436010e-02 -8.09540419e-02 -6.02436012e-03\n",
      " -4.21972029e-02  3.71619947e-02 -3.32408467e-02 -7.59476985e-02\n",
      " -2.53794726e-02  2.46177822e-02 -2.67524640e-02 -1.17603295e-01\n",
      " -2.88379403e-03  5.91991854e-02  2.43440572e-02 -4.10543739e-02\n",
      "  4.72602401e-02  6.36247992e-02  1.14103272e-01  1.59539336e-02\n",
      "  3.51691831e-03  3.38644633e-02 -1.37595639e-01  2.84559140e-03\n",
      " -9.17545720e-02  2.86765089e-02  3.17720634e-02 -4.59743115e-02\n",
      " -3.22025846e-02  7.96621555e-03 -4.17971073e-02 -1.75682629e-03\n",
      " -1.88260372e-02]\n",
      "P-values for coefficients: 0.9999999999999998\n",
      "Omnibus F-statistic: 1.1389838183126514e-31\n",
      "P-value for omnibus F: 1.0\n",
      "\n",
      "Part (b):\n",
      "Regression coefficients for top 3 predictors: [ 2.08861381  0.98862847 -0.07404027]\n",
      "P-values for coefficients: 0.9999999999999998\n",
      "Omnibus F-statistic: -6.433479407753631e-32\n",
      "P-value for omnibus F: nan\n",
      "\n",
      "Part (c):\n",
      "Selected features using LassoCV: [ 0  1  3 18 19 23 25 34 38 52 54 61 72 75 79 81 86 90 92]\n",
      "Regression coefficients for selected features: [ 0.97982199  2.08589912 -0.10968847  0.06606793 -0.03645116  0.09418909\n",
      "  0.0810862   0.05496426 -0.07123434 -0.0497718   0.07259277 -0.0960863\n",
      " -0.0507677  -0.07012064 -0.12892106  0.06209193  0.09875843 -0.10791272\n",
      " -0.1091538 ]\n",
      "P-values for coefficients: 0.9999999999999998\n",
      "Omnibus F-statistic: 7.627458853011841e-32\n",
      "P-value for omnibus F: 1.0\n",
      "\n",
      "Part (d):\n",
      "Selected features using LassoCV: [ 1 51 54 79 81 86 90]\n",
      "Regression coefficients for selected features: [ 2.0855732   0.10754038  0.16486605 -0.09846781  0.15248948  0.1358596\n",
      " -0.15556621]\n",
      "P-values for coefficients: 0.9999999999999997\n",
      "Omnibus F-statistic: 2.9228573677485315e-31\n",
      "P-value for omnibus F: 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, LassoCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "\n",
    "def generate_data(num_samples, num_variables):\n",
    "    np.random.seed(42)\n",
    "    X = np.random.normal(size=(num_samples, num_variables))\n",
    "    y = X[:, 0] + 2 * X[:, 1] + np.random.normal(size=num_samples)\n",
    "    return X, y\n",
    "\n",
    "def perform_regression(X, y):\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    return model.coef_, model.intercept_\n",
    "\n",
    "def perform_t_test(X, y, coef, intercept):\n",
    "    _, p_values = stats.ttest_ind(y, np.dot(X, coef) + intercept)\n",
    "    return p_values\n",
    "\n",
    "def main():\n",
    "    num_samples = 500\n",
    "    num_variables = 101\n",
    "\n",
    "    # Part (a)\n",
    "    X, y = generate_data(num_samples, num_variables)\n",
    "    coef_a, intercept_a = perform_regression(X, y)\n",
    "    p_values_a = perform_t_test(X, y, coef_a, intercept_a)\n",
    "    f_statistic_a, p_value_f_a = stats.f_oneway(y, np.dot(X, coef_a) + intercept_a)\n",
    "\n",
    "    print(\"\\nPart (a):\")\n",
    "    print(\"Regression coefficients:\", coef_a)\n",
    "    print(\"P-values for coefficients:\", p_values_a)\n",
    "    print(\"Omnibus F-statistic:\", f_statistic_a)\n",
    "    print(\"P-value for omnibus F:\", p_value_f_a)\n",
    "\n",
    "    # Part (b)\n",
    "    top_three_indices = np.argsort(np.abs(coef_a))[::-1][:3]\n",
    "    X_b = X[:, top_three_indices]\n",
    "    coef_b, intercept_b = perform_regression(X_b, y)\n",
    "    p_values_b = perform_t_test(X_b, y, coef_b, intercept_b)\n",
    "    f_statistic_b, p_value_f_b = stats.f_oneway(y, np.dot(X_b, coef_b) + intercept_b)\n",
    "\n",
    "    print(\"\\nPart (b):\")\n",
    "    print(\"Regression coefficients for top 3 predictors:\", coef_b)\n",
    "    print(\"P-values for coefficients:\", p_values_b)\n",
    "    print(\"Omnibus F-statistic:\", f_statistic_b)\n",
    "    print(\"P-value for omnibus F:\", p_value_f_b)\n",
    "\n",
    "    # Part (c)\n",
    "    model_cv = LassoCV(cv=5)\n",
    "    model_cv.fit(X, y)\n",
    "    selected_features_c = np.where(model_cv.coef_ != 0)[0]\n",
    "    X_c = X[:, selected_features_c]\n",
    "    coef_c, intercept_c = perform_regression(X_c, y)\n",
    "    p_values_c = perform_t_test(X_c, y, coef_c, intercept_c)\n",
    "    f_statistic_c, p_value_f_c = stats.f_oneway(y, np.dot(X_c, coef_c) + intercept_c)\n",
    "\n",
    "    print(\"\\nPart (c):\")\n",
    "    print(\"Selected features using LassoCV:\", selected_features_c)\n",
    "    print(\"Regression coefficients for selected features:\", coef_c)\n",
    "    print(\"P-values for coefficients:\", p_values_c)\n",
    "    print(\"Omnibus F-statistic:\", f_statistic_c)\n",
    "    print(\"P-value for omnibus F:\", p_value_f_c)\n",
    "\n",
    "    # Part (d)\n",
    "    alphas = np.logspace(-4, 0, 100)\n",
    "    model_cv = LassoCV(alphas=alphas, cv=5)\n",
    "    model_cv.fit(X[:, 1:], y)\n",
    "    coef_d = model_cv.coef_\n",
    "    coef_d = np.insert(coef_d, 0, 0)  # Insert 0 for the intercept\n",
    "    selected_features_d = np.where(coef_d != 0)[0]\n",
    "\n",
    "    if len(selected_features_d) > 0:\n",
    "        X_d = X[:, selected_features_d]\n",
    "        coef_d, intercept_d = perform_regression(X_d, y)\n",
    "        p_values_d = perform_t_test(X_d, y, coef_d, intercept_d)\n",
    "        f_statistic_d, p_value_f_d = stats.f_oneway(y, np.dot(X_d, coef_d) + intercept_d)\n",
    "\n",
    "        print(\"\\nPart (d):\")\n",
    "        print(\"Selected features using LassoCV:\", selected_features_d)\n",
    "        print(\"Regression coefficients for selected features:\", coef_d)\n",
    "        print(\"P-values for coefficients:\", p_values_d)\n",
    "        print(\"Omnibus F-statistic:\", f_statistic_d)\n",
    "        print(\"P-value for omnibus F:\", p_value_f_d)\n",
    "    else:\n",
    "        print(\"\\nPart (d): No features selected by LassoCV.\")\n",
    "\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992f76af",
   "metadata": {},
   "source": [
    "### part e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9094470a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for model from part (b): 71.44605123301606\n",
      "MSE for model from part (c): 71.44605123301606\n",
      "MSE for model from part (d): 70.57577652600214\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Function to generate new data\n",
    "def generate_new_data(n_samples, n_variables):\n",
    "    np.random.seed(0)\n",
    "    X_new = np.random.normal(size=(n_samples, n_variables))\n",
    "    true_model_coefficients = np.random.normal(size=n_variables)\n",
    "    Y_new = np.dot(X_new, true_model_coefficients) + np.random.normal(size=n_samples)\n",
    "    return X_new, Y_new\n",
    "\n",
    "# Generate new data\n",
    "X_new, Y_new = generate_new_data(500, 101)\n",
    "\n",
    "# Model from part (b)\n",
    "selected_feature_indices_b = [2, 1, 0]  \n",
    "model_b = LinearRegression().fit(X_new[:, selected_feature_indices_b], Y_new)\n",
    "mse_b = mean_squared_error(Y_new, model_b.predict(X_new[:, selected_feature_indices_b]))\n",
    "\n",
    "# Model from part (c)\n",
    "selected_feature_indices_c = [0, 1, 2]  \n",
    "model_c = LinearRegression().fit(X_new[:, selected_feature_indices_c], Y_new)\n",
    "mse_c = mean_squared_error(Y_new, model_c.predict(X_new[:, selected_feature_indices_c]))\n",
    "\n",
    "# Model from part (d)\n",
    "selected_feature_indices_d = [0, 6, 3] \n",
    "model_d = LinearRegression().fit(X_new[:, selected_feature_indices_d], Y_new)\n",
    "mse_d = mean_squared_error(Y_new, model_d.predict(X_new[:, selected_feature_indices_d]))\n",
    "\n",
    "# Compare performance of models\n",
    "print(\"MSE for model from part (b):\", mse_b)\n",
    "print(\"MSE for model from part (c):\", mse_c)\n",
    "print(\"MSE for model from part (d):\", mse_d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a1fa92",
   "metadata": {},
   "source": [
    "### part f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd24077b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 1:\n",
      "MSE for model from part (b): 71.44605123301606\n",
      "MSE for model from part (c): 71.44605123301606\n",
      "MSE for model from part (d): 70.57577652600214\n",
      "\n",
      "Experiment 2:\n",
      "MSE for model from part (b): 71.44605123301606\n",
      "MSE for model from part (c): 71.44605123301606\n",
      "MSE for model from part (d): 70.57577652600214\n",
      "\n",
      "Experiment 3:\n",
      "MSE for model from part (b): 71.44605123301606\n",
      "MSE for model from part (c): 71.44605123301606\n",
      "MSE for model from part (d): 70.57577652600214\n",
      "\n",
      "Experiment 4:\n",
      "MSE for model from part (b): 71.44605123301606\n",
      "MSE for model from part (c): 71.44605123301606\n",
      "MSE for model from part (d): 70.57577652600214\n",
      "\n",
      "Experiment 5:\n",
      "MSE for model from part (b): 71.44605123301606\n",
      "MSE for model from part (c): 71.44605123301606\n",
      "MSE for model from part (d): 70.57577652600214\n",
      "\n",
      "Experiment 6:\n",
      "MSE for model from part (b): 71.44605123301606\n",
      "MSE for model from part (c): 71.44605123301606\n",
      "MSE for model from part (d): 70.57577652600214\n",
      "\n",
      "Experiment 7:\n",
      "MSE for model from part (b): 71.44605123301606\n",
      "MSE for model from part (c): 71.44605123301606\n",
      "MSE for model from part (d): 70.57577652600214\n",
      "\n",
      "Experiment 8:\n",
      "MSE for model from part (b): 71.44605123301606\n",
      "MSE for model from part (c): 71.44605123301606\n",
      "MSE for model from part (d): 70.57577652600214\n",
      "\n",
      "Experiment 9:\n",
      "MSE for model from part (b): 71.44605123301606\n",
      "MSE for model from part (c): 71.44605123301606\n",
      "MSE for model from part (d): 70.57577652600214\n",
      "\n",
      "Experiment 10:\n",
      "MSE for model from part (b): 71.44605123301606\n",
      "MSE for model from part (c): 71.44605123301606\n",
      "MSE for model from part (d): 70.57577652600214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Function to generate new data\n",
    "def generate_new_data(n_samples, n_variables):\n",
    "    np.random.seed(0)\n",
    "    X_new = np.random.normal(size=(n_samples, n_variables))\n",
    "    true_model_coefficients = np.random.normal(size=n_variables)\n",
    "    Y_new = np.dot(X_new, true_model_coefficients) + np.random.normal(size=n_samples)\n",
    "    return X_new, Y_new\n",
    "\n",
    "# Number of times to repeat the experiment\n",
    "num_repeats = 10\n",
    "\n",
    "for i in range(num_repeats):\n",
    "    print(f\"Experiment {i+1}:\")\n",
    "    # Generate new data\n",
    "    X_new, Y_new = generate_new_data(500, 101)\n",
    "\n",
    "    # Model from part (b)\n",
    "    selected_feature_indices_b = [2, 1, 0]  \n",
    "    model_b = LinearRegression().fit(X_new[:, selected_feature_indices_b], Y_new)\n",
    "    mse_b = mean_squared_error(Y_new, model_b.predict(X_new[:, selected_feature_indices_b]))\n",
    "\n",
    "    # Model from part (c)\n",
    "    selected_feature_indices_c = [0, 1, 2]  \n",
    "    model_c = LinearRegression().fit(X_new[:, selected_feature_indices_c], Y_new)\n",
    "    mse_c = mean_squared_error(Y_new, model_c.predict(X_new[:, selected_feature_indices_c]))\n",
    "\n",
    "    # Model from part (d)\n",
    "    selected_feature_indices_d = [0, 6, 3]  # Example indices, replace with your selected indices\n",
    "    model_d = LinearRegression().fit(X_new[:, selected_feature_indices_d], Y_new)\n",
    "    mse_d = mean_squared_error(Y_new, model_d.predict(X_new[:, selected_feature_indices_d]))\n",
    "\n",
    "    # Compare performance of models\n",
    "    print(\"MSE for model from part (b):\", mse_b)\n",
    "    print(\"MSE for model from part (c):\", mse_c)\n",
    "    print(\"MSE for model from part (d):\", mse_d)\n",
    "\n",
    "    # Choose the model with the lowest MSE or the best performance metric\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
